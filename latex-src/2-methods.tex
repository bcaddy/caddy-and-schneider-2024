% - [x] disclaimer, this is not new and based on all these sources. We order it slightly differently to work on GPUs so we will outline it here
% - [x] provide summary of integrator first then provide details. Then there's space in the first section to discuss details of the implementation
%  - [ ] How was this implemented on GPUs and what made it different
%    - [ ] what does Cholla do when I press go?
%      - [ ] allocations, data movement, etc
%  - [x] here's the details on all the math

\section{Methods}
\label{sec:methods}

Magnetohydrodynamics is a critical aspect of many astrophysical phenomenon but is extremely computationally expensive. Part of the computational expense is that magnetic field dynamos and their effects occur across a wide range of time and size scales. MHD simulation methods are also complex, the additional waves compared to hydrodynamics and the requirement to maintain the divergence free condition result in considerable complexity.

As such physically realistic MHD simulations need to be both high resolution and use robust, divergence free, methods which increase the computational cost. This requires the ability to harness new exascale, GPU based, supercomputers efficiently and adding MHD to Cholla is an ideal way to do that. In this section we will describe the equations solved and methods used by the MHD module of Cholla with special attention to the changes required for solving these equations on GPUs.

\subsection{Magnetohydrodynamics}
\label{sec:methods-mhd}

Cholla solves the ideal MHD equations in their conserved Eulerian form using a finite volume method. These equations neglect all dissipative processes: finite viscosity, electrical resistivity and thermal conductivity. Since Cholla is focused on simulating the physics of low density regions such as the ISM, CGM, and IGM these approximations are reasonable. Anisotropic conduction may have an impact on galactic dynamics and is planned as a future addition to Cholla.

The ideal MHD equations are:

\begin{equation}
    \label{eqn:mass-conservation}
    \frac{\partial \rho}{\partial t} + \nabla \cdot (\rho \boldsymbol{v}) = 0
\end{equation}

\begin{equation}
    \label{eqn:momentum-conservation}
    \frac{\partial \rho\boldsymbol{v}}{\partial t} + \nabla \cdot (\rho \boldsymbol{v}\otimes\boldsymbol{v} - \boldsymbol{B}\otimes\boldsymbol{B} + P_T\boldsymbol{I}) = 0
\end{equation}

\begin{equation}
    \label{eqn:energy-conservation}
    \frac{\partial E}{\partial t} + \nabla \cdot ( (E + P_T) \boldsymbol{v} + \boldsymbol{B}(\boldsymbol{B}\cdot\boldsymbol{v}) ) = 0
\end{equation}

\begin{equation}
    \label{eqn:induction}
    \frac{\partial \boldsymbol{B}}{\partial t} - \nabla \times (\boldsymbol{v} \times \boldsymbol{B}) = 0
\end{equation}

where $\rho$ is density, $\boldsymbol{v} = ( v_x, v_y, v_z)$ is the velocity vector, $t$ is time, $\boldsymbol{B} = ( B_x, B_y, B_z)$ is the magnetic field, $\boldsymbol{I}$ is the identity tensor, $P_T \equiv P + \frac{1}{2}(\boldsymbol{B} \cdot \boldsymbol{B})$, $E$ is the total energy per unit volume $E \equiv \epsilon + \frac{1}{2}\rho(\boldsymbol{v}\cdot\boldsymbol{v}) + \frac{1}{2}(\boldsymbol{B}\cdot\boldsymbol{B})$, and the units are such that magnetic permeability $\mu_0 = 1$. 

Equation \ref{eqn:mass-conservation} describes the conservation of mass, equation \ref{eqn:momentum-conservation} describes the conservation of momentum, equation \ref{eqn:energy-conservation} describes the conservation of energy, an equation \ref{eqn:induction} is the induction equation which describes the divergence free condition. The equation of state used is the ideal gas equation of state $P \equiv \epsilon(\gamma - 1)$ where $\gamma$ is the adiabatic index and $\epsilon$ is the internal energy density. 

In practice these equations are used in their vector form where $\boldsymbol{U}$ and $\boldsymbol{w}$ and the conserved and primitive variables respectively. 

\begin{equation}
    \boldsymbol{U} = \begin{bmatrix}
            \rho \\
            v_x \\
            v_y \\
            v_z \\
            E   \\
            B_x \\
            B_y \\
            B_z
         \end{bmatrix}, \quad
    \boldsymbol{w} = \begin{bmatrix}
            \rho \\
            v_x \\
            v_y \\
            v_z \\
            P   \\
            B_x \\
            B_y \\
            B_z 
         \end{bmatrix}
\end{equation}


The conservation equations, in Cartesian coordinates, can then be rewritten as

\begin{equation}
    \label{eqn:vector-conserved}
    \frac{\partial \boldsymbol{U}}{\partial t} + 
    \frac{\partial \boldsymbol{F_x}}{\partial x} + 
    \frac{\partial \boldsymbol{F_y}}{\partial y} + 
    \frac{\partial \boldsymbol{F_z}}{\partial z} = 0 
\end{equation}

where $\boldsymbol{F_x}$, $\boldsymbol{F_y}$, and $\boldsymbol{F_z}$ are the vectors of fluxes in the $x$, $y$, and $z$ direction respectively and are given by

\begin{equation}
    \boldsymbol{F_x} = \begin{bmatrix}
            \rho v_{x} \\
            \rho v_{x}^2 + P_{T} - B_{x}^2 \\
            \rho v_{x} v_{y} - B_{x} B_{y} \\
            \rho v_{x} v_{z} - B_{x} B_{z} \\
            v_{x} \left( E + p_{T} \right) - B_{x} \left( \boldsymbol{v} \cdot \boldsymbol{B} \right) \\
            0 \\
            B_{y} v_{x} - B_{x} v_{y} \\
            B_{z} v_{x} - B_{x} v_{z} \\
         \end{bmatrix}
\end{equation}

\begin{equation}
    \boldsymbol{F_y} = \begin{bmatrix}
            \rho v_{y} \\
            \rho v_{y} v_{x} - B_{y} B_{x} \\
            \rho v_{y}^2 + P_{T} - B_{y}^2 \\
            \rho v_{y} v_{z} - B_{y} B_{z} \\
            v_{y} \left( E + P_{T} \right) - B_{y} \left( \boldsymbol{v} \cdot \boldsymbol{B} \right) \\
            B_{x} v_{y} - B_{y} v_{x} \\
            0 \\
            B_{z} v_{y} - B_{y} v_{z} \\
         \end{bmatrix}
\end{equation}

\begin{equation}
    \boldsymbol{F_z} = \begin{bmatrix}
            \rho v_{z} \\
            \rho v_{z} v_{x} - B_{z} B_{x} \\
            \rho v_{z} v_{y} - B_{z} B_{y} \\
            \rho v_{z}^2 + P_{T} - B_{z}^2 \\
            v_{z} \left( E + P_{T} \right) - B_{z} \left( \boldsymbol{v} \cdot \boldsymbol{B} \right) \\
            B_{x} v_{z} - B_{z} v_{x} \\
            B_{y} v_{z} - B_{z} v_{y} \\
            0
         \end{bmatrix}.
\end{equation}

Some other useful MHD equations are given in Appendix \ref{appen:mhd-glossary}.



\subsection{Overview of the VL+CT Integrator}
\label{sec:vlct-summary}

The MHD integrator in Cholla uses the VL+CT (Van Leer plus Constrained Transport) integrator introduced in \cite{stone_2009} and used in Athena and Athena++ since then. The specific algorithm is from \cite{stone_2009} with some clarifying details from \cite{gardiner_2005,gardiner_unsplit_2008,stone_athena_2008} and the piecewise parabolic method is from \cite{felker_2020}. We also use the HLLD Riemann solver from \cite{hlld_2005}.

The VL+CT integrator is very similar in structure to the Van Leer integrator, though with significant new additions for Constrained Transport (CT). Constrained transport treats the magnetic field as surface averaged quantity centered at cell interfaces rather than a volume averaged, cell centered quantity like the hydro variables. Also, each face stores only the magnetic field perpendicular to that face, i.e. the $x,i+1/2,j,k$ face store the $B_{x,i+1/2,j,k}$ magnetic field. The magnetic field is then updated with edge averaged EMFs (Electromotive Force) computed from the magnetic flux returned by the Riemann solver. By updating with EMF you automatically fulfill the divergence free condition for magnetic fields, assuming that the initial conditions are divergence free.

The steps of the VL+CT integrator are as follows; more detailed discussion of each step is in section \ref{vlct:header}.

\begin{enumerate}
    \item Compute the time step
    \item Perform piecewise constant reconstruction of the interface state
    \item Perform a Riemann solve on the reconstructed interface state
    \item Compute the edge centered electric fields
    \item Update the $t=n$ conserved variables to $t=n+\delta t/2$ using the computed fluxes and electric fields
    \item Perform piecewise linear or parabolic reconstruction of the interface state
    \item Perform a Riemann solve on the higher order reconstructed interface state
    \item Compute the edge centered electric fields
    \item Update the $t=n$ conserved variables to $t=n+\delta t$ using the half time step fluxes and electric fields
\end{enumerate}

\subsection{Implementation on GPUs}

While the implementation of MHD on GPUs is similar to the implementation on CPUs there are some crucial differences, especially in data handling and movement. Compared to CPUs, GPUs have high memory bandwidth and extremely high FLOPS but limited memory capacity and limited functionality due to their fundamentally SIMD nature. Also, while their memory bandwidth is higher the much larger number of active threads on a GPU compared to a CPU still means that codes are often limited by memory bandwidth. As an example of this, where Athena++ computed their centered magnetic fields once and then saves them to memory Cholla recomputes them as needed. This saves a considerable amount of GPU memory and has minimal impact on performance due to the high memory bandwidth and FLOPS of GPUs.

A major change since earlier versions of Cholla is keeping as much data as possible in the GPU memory instead of moving it to and from main system memory. Historically Cholla, and many other GPU codes, have kept the "primary" data on the CPU memory, copied whatever data needed worked on to the GPU, computed with it, then copied the data back. As GPUs have gotten dramatically faster and with much more memory over the last decade it had gotten to the point where these copies to and fro dominate the run time. In addition, new supercomputers, such as Frontier, have the network connections directly connected to the GPUs instead of connected to the CPU and so any MPI communication has to go through GPU memory. Between these two factors it is critical that all the data lives on the GPU and stays there during the entire simulation. Cholla has successfully moved all computations and MPI communication to the GPU. The only work that remains on the CPU is the setting of the initial conditions, which only occurs once, and reading and writing the HDF5 files since, at the time of writing, the HDF5 library does not support writing files directly from GPU memory.

These, and other changes (TODO: EVAN, what else should we add?) has dramatically improved Cholla performance over the last few years; in total a NUMBERX speed up on the same hardware and a NUMBERX total speed up moving from running on Summit on 2019 to Frontier in 2023.

INSERT 2019 vs. 2023 SCALING PLOT HERE.

% ===========================================================================
\subsection{VL+CT Integrator in Detail}
\label{vlct:header}

\subsubsection{Step 1: Compute the Time Step}
\label{vlct:dt}

The first step is to compute the time step. This it the minimum crossing time of any wave in any cell multiplied by a Courant factor to maintain the Courant–Friedrichs–Lewy condition.

\begin{equation}
    \label{eqn:dt}
    \delta t = C_{CFL} \min \left(
        \frac{\delta x}{\mid v^n_{x,i,j,k} \mid + C^n_{f,i,j,k}},
        \frac{\delta y}{\mid v^n_{y,i,j,k} \mid + C^n_{f,i,j,k}},
        \frac{\delta z}{\mid v^n_{z,i,j,k} \mid + C^n_{f,i,j,k}}
    \right).
\end{equation}

Where $\delta t$ is the time step, $C_{CFL} \leq 0.5$ is the CFL number, $\mid v^n_{l,i,j,k}\mid $ is the magnitude of the velocity in the $l$ direction velocity in the ${i,j,k}$ cell, and $C^n_f $ is the fast magnetosonic wave-speed computed using \emph{cell centered} values. The fast and slow magnetosonic speeds are computed with this equation

\begin{equation}
    c_{f,s} = \sqrt{\frac
    {\gamma p + \mid \boldsymbol{B} \mid^2 \pm \sqrt{\left( \gamma p \;+ \mid \boldsymbol{B} \mid^2 \right)^2 - 4\gamma p B_x^2 } }
    {2\rho}}
\end{equation}

where the $+$ option corresponds to the fast magnetosonic speed.

Equation \ref{eqn:dt} computes the minimum crossing time of a wave in a specific cell and then a global reduction is performed to find the minimum in the entire grid; that minimum is used as the time step $\delta t$. This reduction is done primarily on the GPU followed by an MPI ALL\_REDUCE. GPU reductions are complex and their performance is extremely sensitive to the method used. We utilized a similar method to what is recommended by NVIDIA\footnote{https://developer.nvidia.com/blog/faster-parallel-reductions-kepler/}. The first step is to do as much of the reduction as possible without communicating between the GPU threads. To do so we launch only the maximum number of threads the GPU can run at once, instead of one thread per cell as is done in most of our kernels. Each thread then performs a grid-stride loop so that most of the reduction is done with no communication between threads at all. Once the grid-stride loop is complete a per-warp reduction is performed using the \texttt{\_\_shfl\_down} intrinsic to find the minimum crossing time within that warp and that is written to shared memory. Next the first warp in each block loads the minimums from shared memory and repeats the \texttt{\_\_shfl\_down} reduction to get the minimum value within the block. The final step is to use the built in atomic operations to perform the final grid wide reduction. In total this method eliminates the need for a second kernel launch to perform, is more performant than a reduction entirely in shared memory, and reduces the number of atomic calls to such a small value, only about 100-150, that they rarely collide in practice. One challenge was that, at the time of writing, CUDA did not have an overload for \texttt{atomicMax} that supported double precision floating point numbers. Instead we adopted a method from RAPIDS cuML library\footnote{https://github.com/rapidsai/cuml/blob/dc14361ba11c41f7a4e1e6a3625bbadd0f52daf7/cpp/src\_prims/stats/minmax.cuh} that uses the 64 bit integer version of \texttt{atomicMax} with some encoding to ensure correct results; no such workaround was required for HIP since HIP supports \texttt{atomicMax} with doubles. This reduction method is used in several other places that Cholla requires reductions as well.

Computing the cell centered magnetic field is done with a direct average of the face centered values. These cell centered values for the magnetic field will then be used several times throughout the integrator. In CPU based codes it is typically more efficient to compute these cell centered magnetic fields once and save them since CPU based codes are typically compute limited. Cholla is generally limited instead by GPU memory or memory bandwidth and so these values are recomputed when needed rather than allocating another large chunk of memory.

\begin{equation}
    \begin{aligned}
        B^n_{x,i,j,k,} = \frac{1}{2} \left( B^n_{x,i+1/2,j,k} + B^n_{x,i-1/2,j,k} \right) \\
        B^n_{y,i,j,k,} = \frac{1}{2} \left( B^n_{y,i,j+1/2,k} + B^n_{y,i,j-1/2,k} \right) \\
        B^n_{z,i,j,k,} = \frac{1}{2} \left( B^n_{z,i,j,k+1/2} + B^n_{z,i,j,k-1/2} \right) \\
    \end{aligned}
\end{equation}

\subsubsection{Step 2: First Order Reconstruction}
\label{vlct:first-order-reconstruction}

Reconstructing the interface states at first order, or piecewise constant (PCM), is done by setting the primitive interface states values to the same value as the cell. PCM is far too diffusive for most simulations but is excellent for debugging or some rare problems where the extra diffusion is desirable. It is worth noting that most higher order methods essentially revert to PCM near large discontinuities.

\begin{equation}
    \boldsymbol{W}_{L, i+1/2} = \boldsymbol{W}_{R, i-1/2} = \boldsymbol{W}_{i}
\end{equation}

where $ \boldsymbol{W}_{L/R, i\pm1/2} $ is the state on the left or right side of the cell

\subsubsection{Step 3: First Riemann Solve}
\label{vlct:first-riemann-solve}

The next step is the solve the Riemann problem with the first order interface states. We use the HLLD Riemann Solver introduced in \cite{hlld_2005}. The longitudinal magnetic field does not require reconstruction and can be used directly since it is stored at the face. The transverse fields (i.e. the fields parallel to the interface) are reconstructed from the cell centered average as shown in section \ref{vlct:dt} then reconstructed using PCM identically to other fields.

The magnetic fluxes that are returned by the Riemann solver are the face centered EMFs (section 5.3 of \cite{stone_athena_2008}), however it is not immediately clear which face centered EMFs they are. Table \ref{table:emf} details the correlation between flux and EMF.

\begin{table}[!ht]
    \centering
        \caption{Magnetic Flux to Face Centered EMF}
    \begin{tabular}{|l|l|l|l|}
    \hline
        HLLD Solve Direction & Equation for Magnetic Flux & Eqn. as a Cross Product & EMF \\ \hline
        $ X $ & $ V_x B_y - B_x V_y $ & $  (V \times B)_z $ & $ -\varepsilon_z $ \\ \hline
        $ X $ & $ V_x B_z - B_x V_z $ & $ -(V \times B)_y $ & $  \varepsilon_y $ \\ \hline
        $ Y $ & $ V_x B_y - B_x V_y $ & $  (V \times B)_z $ & $ -\varepsilon_x $ \\ \hline
        $ Y $ & $ V_x B_z - B_x V_z $ & $ -(V \times B)_y $ & $  \varepsilon_z $ \\ \hline
        $ Z $ & $ V_x B_y - B_x V_y $ & $  (V \times B)_z $ & $ -\varepsilon_y $ \\ \hline
        $ Z $ & $ V_x B_z - B_x V_z $ & $ -(V \times B)_y $ & $  \varepsilon_x $ \\ \hline
    \end{tabular}
    \tablecomments{The directions used here are relative to the internal workings of the HLLD solver. Since the HLLD solver is inherently 1D we run it once for each of the faces of a cell. So in the case where the solver is running in the Y direction the solver's Y field is actually the Z field and the solvers Z field is actually the X field, cyclically extended for the Z direction}
    \label{table:emf}
\end{table}

\subsubsection{Step 4: Compute the Constrained Transport EMF}
\label{vlct:emf}

The next step is to calculate the constrained transport EMF. These fields are \emph{line averaged} along each cell vertex. These line averaged fields are constructed by a complex averaging of the face centered EMF, from the previous step, and their slopes.

% I don't think we need this 
% Technically constrained transport uses the magnetic flux as the conservative variable and EMF to update it. However, those values only differ from the magnetic flux density (i.e. the magnetic field) and the electric field respectively by factors of unit length we can treat them as the same thing, the same way we treat density and mass as the same for the hydro fields \cite{stone_athena_2008}. As such we use the magnetic field and electric field to evolve the grid. Electric fields have the proper units to evolve the magnetic flux density, $ B $, whereas EMF has the proper units to evolve the magnetic flux.

On any face there are two non-zero electric fields; both transverse to the face. The most important thing to note is that the component that is used to calculate the field along a given edge is the component that is parallel to that edge. i.e. if the edge points along the $ z $-direction then you use the field pointing along the $ z $-direction, not the field in the $ x $ or $ y $ direction.

We also need cell centered electric fields (reference fields) for computing the slopes. This reference field can be computed with the following cross product

\begin{equation}
    \mathcal{E}_{i,j,k}^{ref,n} = - \left( \boldsymbol{v}^{n}_{i.j.k} \times \boldsymbol{B}^{n}_{i.j.k} \right).
\end{equation}

Example for computing the CT electric field in the $ z $-direction. The other direction can be computed by just substituting out the $ z $ index with $ x $ or $ y $ and changing the derivatives appropriately, see Figure \ref{fig:emf-graph} for more details.

\begin{equation}
    \label{eqn:emf-edge}
    \begin{aligned}
        \mathcal{E}_{z, i-1/2, j-1/2, k} = \frac{1}{4} \left(
              \mathcal{E}_{z, i-1/2, j, k}
            + \mathcal{E}_{z, i, j-1/2, k}
            + \mathcal{E}_{z, i-1/2, j-1, k}
            + \mathcal{E}_{z, i-1, j-1/2, k}\right) \\
        + \frac{\delta y}{8} \left( \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i-1/2, j-1/4, k} + \left(  \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i-1/2, j-3/4, k} \right) \\
        + \frac{\delta x}{8} \left( \left( \frac{\partial \mathcal{E}_z }{\partial x} \right)_{i-1/4, j-1/2, k} + \left(  \frac{\partial \mathcal{E}_z }{\partial x} \right)_{i-3/4, j-1/2, k} \right)
    \end{aligned}
\end{equation}

Where the derivatives are computed using the upwinded slope as follows

\begin{equation}
    \label{eqn:emf-upwind-slope}
    \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i-1/2, j-1/4, k} =
        \begin{cases}
            \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i-1, j-1/4, k} & \text{for} \; v_{x, i-1/2} > 0
            \\
            \\
            \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i, j-1/4, k} & \text{for} \; v_{x, i-1/2} < 0
            \\
            \\
            \frac{1}{2} \left( \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i-1, j-1/4, k} + \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i, j-1/4, k} \right) & \text{otherwise}
            \\
            \\
        \end{cases}
\end{equation}

where, for example, the derivatives are given by

\begin{equation}
    \label{eqn:emf-slope}
    \left( \frac{\partial \mathcal{E}_z }{\partial y} \right)_{i, j-1/4, k} =
    2 \left( \frac{\mathcal{E}_{z,i,j-1/2,k} - \mathcal{E}_{z,i,j,k}^{ref}}{\delta y} \right).
\end{equation}

The easiest way to see how to compute these derivatives is with the Figure \ref{fig:emf-graph} based off of Figure 5 in \cite{stone_athena_2008}. Each edge requires 4 derivatives and they are computed as differences between a reference state and an edge state.

\begin{figure}[ht!]
    \epsscale{0.5}
    \plotone{assets/2-methods/CT-edge-field-figures-X.pdf}
    \plotone{assets/2-methods/CT-edge-field-figures-Y.pdf}
    \plotone{assets/2-methods/CT-edge-field-figures-Z.pdf}
    \caption{2D slices in all three planes showing the location of the fluxes, edge EMFs, and derivatives. Based on Figure 5 of \cite{stone_athena_2008}.}
    \label{fig:emf-graph}
\end{figure}

\subsubsection{Step 5. Perform the Half Time-step Update}
\label{vlct:half-dt-update}

Update all the hydro variables using the standard update equation

\begin{equation}
    \begin{aligned}
        \boldsymbol{U}^{n+1/2}_{i,j,k} = \boldsymbol{U}^{n}_{i,j,k}
        - \frac{\delta t}{\delta x} \left( \boldsymbol{F}^n_{x,i+1/2,j,k} - \boldsymbol{F}^n_{x,i-1/2,j,k} \right) \\
        - \frac{\delta t}{\delta y} \left( \boldsymbol{F}^n_{y,i+1/2,j,k} - \boldsymbol{F}^n_{y,i-1/2,j,k} \right) \\
        - \frac{\delta t}{\delta z} \left( \boldsymbol{F}^n_{z,i+1/2,j,k} - \boldsymbol{F}^n_{z,i-1/2,j,k} \right).
    \end{aligned}
\end{equation}

Update the magnetic field using the electric fields

\begin{equation}
    \begin{aligned}
        B^{n+1/2}_{x,i-1/2,j,k} = B^{n}_{x,i-1/2,j,k}
        + \frac{\delta t}{\delta z} \left( \mathcal{E}^n_{y,i-1/2,j,k+1/2} - \mathcal{E}^n_{y,i-1/2,j,k-1/2} \right) \\
        - \frac{\delta t}{\delta y} \left( \mathcal{E}^n_{z,i-1/2,j+1/2,k} - \mathcal{E}^n_{z,i-1/2,j-1/2,k} \right)
    \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
        B^{n+1/2}_{y,i,j-1/2,k} = B^{n}_{y,i,j-1/2,k}
        + \frac{\delta t}{\delta x} \left( \mathcal{E}^n_{z,i+1/2,j-1/2,k} - \mathcal{E}^n_{z,i-1/2,j-1/2,k} \right) \\
        - \frac{\delta t}{\delta z} \left( \mathcal{E}^n_{x,i,j-1/2,k+1/2} - \mathcal{E}^n_{x,i,j-1/2,k-1/2} \right)
    \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
        B^{n+1/2}_{z,i,j,k-1/2} = B^{n}_{z,i-1/2,j,k}
        + \frac{\delta t}{\delta y} \left( \mathcal{E}^n_{x,i,j+1/2,k-1/2} - \mathcal{E}^n_{x,i,j-1/2,k-1/2} \right) \\
        - \frac{\delta t}{\delta x} \left( \mathcal{E}^n_{y,i+1/2,j,k-1/2} - \mathcal{E}^n_{y,i-1/2,j,k-1/2} \right).
    \end{aligned}
\end{equation}

\subsubsection{Step 6. Half Time-step Second Order Reconstruction}
\label{vlct:higher-order-reconstruction}

Now we need to perform the higher order reconstruction. The method shown here is for Piecewise Linear Method (PLM), reconstruction. Cholla currently implements piecewise constant, piecewise linear and piecewise parabolic reconstruction, with limiting in the characteristic variables, for MHD. The piecewise parabolic method that Cholla utilizes is discussed in detail in \cite{felker_2020}. Using the third order piecewise parabolic method does typically give slightly more accurate results but since the method is formally second order it does not improve the overall scaling.

Note that at a given face only the transverse components of the electric field need to be reconstructed. The longitudinal component is already given at the face.

\begin{enumerate}
    \item Compute the primitive variables
    
    \item Compute the left, right, centered, and Van Leer differences in the primitive variables
    \begin{align} 
        \delta \boldsymbol{w}_{L,i} = \boldsymbol{w_{i}} - \boldsymbol{w_{i-1}} \\ 
        \delta \boldsymbol{w}_{R,i} = \boldsymbol{w_{i+1}} - \boldsymbol{w_{i}} \\
        \delta \boldsymbol{w}_{C,i} = \frac{\boldsymbol{w_{i+1}} - \boldsymbol{w_{i-1}}}{2} \\
        \delta \boldsymbol{w}_{VL,i} = 
        \begin{cases}
            \frac{2 \boldsymbol{w}_{L,i} \boldsymbol{w}_{R,i}}{\boldsymbol{w}_{L,i} +\boldsymbol{w}_{R,i}} ,& \text{if } \boldsymbol{w}_{L,i} \boldsymbol{w}_{R,i} > 0\\
            0,              & \text{otherwise}
        \end{cases}
    \end{align}
    
    \item Project the slopes into the characteristic variables $\boldsymbol{a}$ using the eigenvectors detailed in \cite{stone_athena_2008}. Note that to maintain mathematical consistency we use the eigenvectors of the $\boldsymbol{w_{i}}$ cell for all three slopes and the later projection back to primitive variables.
    \item Apply monotonicity constraints to the characteristic differences to ensure that the reconstruction is total variation diminishing (TVD). We used this limiter from \cite{leveque2002finite}.
    \begin{equation}
        \label{eqn:limiter}
        \delta \boldsymbol{a}_{m,i} = 
        \begin{cases}
             \text{sgn}(\boldsymbol{a}_{C,i})\min(2\abs{\boldsymbol{a}_{L,i}},2\abs{\boldsymbol{a}_{R,i}},\abs{\boldsymbol{a}_{C,i}},\abs{\boldsymbol{a}_{VL,i}}),& \text{if } \boldsymbol{a}_{L,i} \boldsymbol{a}_{R,i} > 0\\
            0,              & \text{otherwise}
        \end{cases}
    \end{equation}
    \item Project the characteristic slopes back into the primitive variables $\boldsymbol{a}$ using the eigenvectors detailed in \cite{stone_athena_2008}.
    \item Then compute the interface states $\boldsymbol{W}_{L, i+1/2}$ and $\boldsymbol{W}_{R, i-1/2}$
\end{enumerate}

    \begin{equation}
        \begin{aligned}
            \boldsymbol{W}_{L, i+1/2} = \boldsymbol{W}_{i} + \frac{\delta \boldsymbol{W}_{i}^m}{2} \\
            \boldsymbol{W}_{R, i-1/2} = \boldsymbol{W}_{i} - \frac{\delta \boldsymbol{W}_{i}^m}{2} \\
        \end{aligned}
    \end{equation}

    where $ \boldsymbol{W}_{L/R, i\pm1/2} $ is the state on the left or right side
    of the cell and $ \delta \boldsymbol{W}_{i}^m $ is the monotonically limited
    primitive slope. Limiting can be done in the primitive variables by skipping steps 3 and 5 then replacing the characteristic slopes in Equation \ref{eqn:limiter} with their primitive counterparts.

\subsubsection{Step 7. Second Riemann Solve}
\label{vlct:2nd-riemann-solve}

Solve the Riemann problem again with the half time step MHD interface states from step 6.

\subsubsection{Step 8. Compute the Constrained Transport Electric Fields}
\label{vlct:2nd-emf}

Repeat step 3 but using the fluxes from the second Riemann solve and the half time step MHD variables.

\subsubsection{Step 9. Perform the Full Time-step Update}
\label{vlct:full-dt-update}

Update all the hydro variables using the below equations. Note that this is almost identical to step 3 except we're updating the $ t = n $ state with the $ t=n+1/2 $ fluxes/CT fields instead of the $ t=n $ fluxes/CT fields

\begin{equation}
    \begin{aligned}
        \boldsymbol{U}^{n+1}_{i,j,k} = \boldsymbol{U}^{n}_{i,j,k}
        - \frac{\delta t}{\delta x} \left( \boldsymbol{F}^{n+1/2}_{x,i+1/2,j,k} - \boldsymbol{F}^{n+1/2}_{x,i-1/2,j,k} \right) \\
        - \frac{\delta t}{\delta y} \left( \boldsymbol{F}^{n+1/2}_{y,i+1/2,j,k} - \boldsymbol{F}^{n+1/2}_{y,i-1/2,j,k} \right) \\
        - \frac{\delta t}{\delta z} \left( \boldsymbol{F}^{n+1/2}_{z,i+1/2,j,k} - \boldsymbol{F}^{n+1/2}_{z,i-1/2,j,k} \right).
    \end{aligned}
\end{equation}

Update the magnetic field

\begin{equation}
    \begin{aligned}
        B^{n+1}_{x,i-1/2,j,k} = B^{n}_{x,i-1/2,j,k}
        + \frac{\delta t}{\delta z} \left( \mathcal{E}^{n+1/2}_{y,i-1/2,j,k+1/2} - \mathcal{E}^{n+1/2}_{y,i-1/2,j,k-1/2} \right) \\
        - \frac{\delta t}{\delta y} \left( \mathcal{E}^{n+1/2}_{z,i-1/2,j+1/2,k} - \mathcal{E}^{n+1/2}_{z,i-1/2,j-1/2,k} \right)
    \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
        B^{n+1}_{y,i,j-1/2,k} = B^{n}_{y,i,j-1/2,k}
        + \frac{\delta t}{\delta x} \left( \mathcal{E}^{n+1/2}_{z,i+1/2,j-1/2,k} - \mathcal{E}^{n+1/2}_{z,i-1/2,j-1/2,k} \right) \\
        - \frac{\delta t}{\delta z} \left( \mathcal{E}^{n+1/2}_{x,i,j-1/2,k+1/2} - \mathcal{E}^{n+1/2}_{x,i,j-1/2,k-1/2} \right)
    \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
        B^{n+1}_{z,i-1/2,j,k} = B^{n}_{z,i-1/2,j,k}
        + \frac{\delta t}{\delta y} \left( \mathcal{E}^{n+1/2}_{x,i,j+1/2,k-1/2} - \mathcal{E}^{n+1/2}_{x,i,j-1/2,k-1/2} \right) \\
        - \frac{\delta t}{\delta x} \left( \mathcal{E}^{n+1/2}_{y,i+1/2,j,k-1/2} - \mathcal{E}^{n+1/2}_{y,i-1/2,j,k-1/2} \right).
    \end{aligned}
\end{equation}

\subsubsection{Step 10. Increment the Time by \texorpdfstring{$\delta t$}{dt}}
\label{vlct:increment-time}

Increment the time by $\delta t$, perform boundary conditions, other physics, etc. then restart at step 1.
