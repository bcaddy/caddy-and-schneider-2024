\section{Automated Testing \& Continuous Integration}
\label{sec:testing}

As Cholla has continued to grow in complexity, and with the continued addition of large new physics modules like MHD that require changes to much of the code base, the need for a more robust, automated testing system has become increasingly apparent. Several challenges exist in implementing such a system for Cholla - not only must the testing system accommodate GPU hardware, but it must also work on large parallel systems like \textit{Frontier}. We have addressed this need in three primary steps: 1) Choosing a testing framework for unit tests, 2) Writing the software tools needed to extend that testing framework for Cholla's needs, and 3) adding automated testing as part of a continuous integration (CI) pipeline that runs whenever anyone submits a pull request to the Cholla GitHub repository. This Section describes the implementation of our automated testing and continuous integration framework.

Taken together, the ability to add tests for any part of the code and their automated running on every pull request has meant that new features are faster and easier to add to Cholla with confidence. Any errors or changes that break older code will likely be quickly caught by the tests before they ever make it into Cholla and have been successful in doing so.

\subsection{Unit Testing Framework}
\label{sec:testing-framework}

There are three main kinds of tests that we need for scientific code bases: unit tests, integration tests, and system tests (also called ``end-to-end" tests). Unit tests check that a single ``unit" of code, a single function, class method, data structure, etc. Integration tests check how units of code operate together. For example, a test of the HLLD solver is an integration test because the solver internally calls many different functions and uses multiple different data structures. System tests check the entire code base, often with a simple test problem like a Riemann problem or linear wave, and verify that the entire program produces the correct output.

GoogleTest\footnote{https://github.com/google/googletest} was chosen for as the testing framework. We chose GoogleTest for the unit testing framework due to its large number of features, general popularity, and relative ease of use. Another primary requirement was a testing framework that supports death tests, tests that check if the internals of the test crash/segfault/etc. Since Cholla, like many HPC codes, handles errors by reporting those errors and then exiting, a testing framework that can handle code crashes without crashing the tests as well is critical. GoogleTest is available already built on most of the HPC systems that we utilized and, if it is not available, can be built as an optional part of the test running script.

\subsection{Extensions for Cholla}

Two primary extensions were required for fully testing Cholla: a robust method for comparing floating point numbers and a way to run system tests.

\subsubsection{Floating Point Comparisons}
\label{sec:fp-comparing}

In order to run either unit tests or system tests, the code must have a robust method for comparing floating point numbers for equality. Comparing floating point numbers for equality is a notoriously challenging\footnote{https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/} and generally the exact comparison method that should be used varies by application. Absolute comparisons ($|a-b| < X$) work well for small numbers, but with larger numbers the difference between two successive floats can be much larger than a typical value for $X$ and therefore a different comparison method is required. We chose a hybrid method of both an absolute comparison and a Units in Last Place (ULP) comparison. A ULP comparison determines how many representable floating point numbers there are between any two floats. By default the hybrid method first performs an absolute check, $|a-b| < 10^{-14}$. This number was chosen as we found that typical differences in the Sod Shock Tube solution when comparing results with different hardware and compilers resulted in differences of $\sim5\times10^{-15}$. After the absolute check a ULP check is performed with a maximum allowed error of 4. If either check passes then the numbers are deemed to be ``equal". GoogleTest does provide utilities to compare floating point numbers but they only utilize the ULP check which often fails when checking small numbers for equality.

\subsubsection{System Tests}

GoogleTest provides most of the tools required to run unit and integration tests, but validating the results of an entire system test is much more complex. Running a system test requires launching the program to test with correct initial conditions, checking that the program did not crash, loading both the generated data to test and the fiducial data, then comparing those two data sets. In order to perform system tests with Cholla, we added a class that performs all of the required tasks, which include launching Cholla with any number of MPI ranks as well as comparing the results against fiducial data. To facilitate running on across a wide range of MPI ranks and on clusters with queue systems, the class is designed to allow system tests to be run in different modes: one can either launch Cholla and save the results, compare already existing test data to fiducial data, or do both. This enables the user to run Cholla on many thousands of ranks then later launch a separate job to make the actual comparison. We have found that on up to 10,000 ranks, with small simulation grids (typically $<64^3 cells$) per rank the latter comparison only takes a few minutes on a single CPU core. Most of the time however, both steps can be run within the same job, since large tests with many ranks are not required for most development work.

Two primary methods of comparison are used to determine the success of a system test. These are either a direct cell-by-cell comparison of the results for each field using the floating point comparison tools described above (Section \ref{sec:fp-comparing}), or a calculation of the L2 norm of the L1 error vector as described in Section  \ref{sec:lwc}. The cell-by-cell comparison is quite accurate, but can be fragile on some complex tests if a small number of cells have errors that are slightly larger than typical which and can lead to false failures when comparing results between systems or compilers. The L2 norm method is less fragile to small errors in a handful of cells, but is generally less sensitive so we only use it on the tests where it is required, namely the MHD blast wave (\autoref{sec:mhd-blast}) and advecting field loop (\autoref{sec:afl}). Both methods are used since the L2 norm method can give false passes when a large number of cells are slightly off as is common if the test has erroneous oscillations, the cell-by-cell comparison does an excellent job of catching those kinds of errors in is also a more stringent comparison method.
 
\subsection{Automated Testing}

To ensure that these tests are run regularly and all new code is tested we have made the existing tests as easy to run as possible, and we require that they are all are run automatically on each pull request. To facilitate this, Cholla's build directory includes a script which performs all required setup, installs GoogleTest (if requested), builds Cholla, and then runs all the tests. The script also includes a function that combines all of these into a single function call for ease of use, for example, if a user is running tests manually (say, prior to submitting a PR). 

Implementing automated testing is not always an easy task. Automated tests are an aspect of Continuous Integration (CI) is the practice of automating the addition of code changes and additions from a team of developers into a software project. Cholla is currently designed to run on CUDA or HIP capable GPUs, so GPU hardware is required in order to incorporate continuous integration (CI) -- something that few current CI services offer at a reasonable cost for academic users. Our solution to this issue was to use a mix of two different systems. When a pull request is submitted to the Cholla GitHub repository several jobs are launched: A GitHub Actions job to check code formatting, a GitHub actions matrix job to build all the HIP/AMD builds, and a Jenkins matrix job running on CRC hardware that runs the CUDA builds, tests, and static analyzers. Thus, every common configuration of Cholla is built with both CUDA and HIP on every pull request and the CUDA builds are also tested to ensure that no existing or new tests fail. 



