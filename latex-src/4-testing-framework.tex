\section{Automated Testing \& Continuous Integration}
\label{sec:testing}

As Cholla has continued to grow in complexity, and with the continued addition of large new physics modules like MHD that require changes to much of the code base, the need for a more robust, automated testing system has become increasingly apparent. Several challenges exist in implementing such a system for Cholla - not only must the testing system accommodate GPU hardware, but it must also work on large parallel systems like \textit{Frontier}. We have addressed this need in three primary steps: 1) Choosing a testing framework for unit tests, 2) Writing the software tools needed to extend that testing framework for Cholla's needs, and 3) adding automated testing as part of a continuous integration (CI) pipeline that runs whenever anyone submits a pull request to the Cholla GitHub repository. This Section describes the implementation of our automated testing and continuous integration framework.

Taken together, the ease of writing and running tests and their automated running on every pull request has meant that new features are faster and easier to add to Cholla with confidence. Any errors or changes that break older code will likely be quickly caught by the tests before they ever make it into Cholla and have been successful in doing so.

\subsection{Unit Testing Framework}
\label{sec:testing-framework}

GoogleTest\footnote{https://github.com/google/googletest} was chosen for as the testing framework. While there are many C++ testing frameworks available, GoogleTest is one of the most fully featured, popular, and easy to use options. Another primary requirement was a testing framework that supports death tests, tests that check if the internals of the test crash/segfault/etc. Since Cholla, like many HPC codes, handles errors by reporting those errors and then exiting, a testing framework that can handle code crashes without crashing the tests as well is critical.

GoogleTest was reasonably easy to integrate into the build system for Cholla and is available already built as a module on many HPC systems. Building it from scratch is also fairly easy and is an optional part of the test running script. We have found GoogleTest to be easy to use, flexible, and extensible. The only major issues we have had is that any functions that contain GoogleTest assertions must be void functions with no returns and since GoogleTest is a macro library it can lead to false positives when the codebase is being examined by a static analyzer such as clang-tidy.

\subsection{Extensions for Cholla}

Two primary extensions were required for fully testing Cholla: a robust method for comparing floating point numbers, and a way to run system tests, that is, tests of the entire code running some kind of test problem.

\subsubsection{Floating Point Comparisons}
\label{sec:fp-comparing}

When testing a numerical code the most important thing is a robust method for comparing the end result, i.e. floating point numbers. Comparing floating point numbers is notoriously challenging\footnote{https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/} and generally the exact comparison method that should be used varies by application. Absolute comparisons ($|a-b| < X$) work well for small numbers, but with larger numbers the difference between two successive floats can be much larger than a typical value for $X$, so generally some kind of relative error test performs best. We chose a hybrid method of both an absolute comparison and a Units in Last Place (ULP) comparison. A ULP comparison determines how many representable floating point numbers there are between any two floats. By default the hybrid method first checks if the two test numbers are within $10^{-14}$ of each other. This number was chosen as we found that typical errors in the Sod Shock Tube when comparing results with different hardware and compilers resulted in errors of $\sim5\times10^{-15}$. After the absolute check a ULP check is performed with a maximum allowed error of 4. If either check passes then the numbers are deemed to be ``equal".

\subsubsection{System Tests}

GoogleTest provides all the tools required to run unit and integration tests, but validating the results of an entire system test is much more complex. In order to perform system tests with Cholla, we added a class that performs all of the required tasks, which include launching Cholla with any number of MPI ranks as well as comparing the results against fiducial data. This class also had to work well when running Cholla with a single MPI rank all the way up to tens of thousands of ranks. To facilitate running on across a wide range of MPI ranks and on clusters with queue systems, the class is designed to allow system tests to be run in different modes: one can either launch Cholla and save the results, compare already existing test data to fiducial data, or do both. This enables the user to run Cholla on many thousands of ranks then later launch a separate job to make the actual comparison. We have found that on up to 10,000 ranks, with small grids per rank the latter comparison only takes a few minutes. Most of the time however, both steps can be run within the same job, since large tests with many ranks are not required for most development work.

Two primary methods of comparison are used to determine the success of a system test. These are either a direct cell-by-cell comparison of the results for each field using the floating point comparison tools described above (Section \ref{sec:fp-comparing}), or a calculation of the L2 norm of the L1 error vector as described in Section  \ref{sec:lwc}. The cell-by-cell comparison is quite accurate, but can be fragile on some complex tests if a small number of cells have slightly larger errors and can lead to false failures when comparing results between systems or compilers. The L2 norm method is less fragile to small errors in a handful of cells, but is generally less sensitive so we only use it on the tests where it is required, namely the MHD blast wave (\autoref{sec:mhd-blast}) and advecting field loop (\autoref{sec:afl}).

\subsection{Automated Testing}

All of this work on testing and writing tests is only useful if the tests are actually run and all new code is required to pass the tests. To this end we have made the existing tests as easy to run as possible, and we require that they are all are run automatically on each pull request. To this end To faciliate this, Cholla's build directory includes a script that sets up the tests, installs GoogleTest (if requested), builds Cholla, and runs all the tests. The script also includes a function that combines all of these into a single function call for ease of use, for example, if a user is running tests manually (say, prior to submitting a PR). 

Automated testing was more complex. Cholla is currently designed to run on CUDA or HIP capable GPUs, so GPU hardware is required in order to incorporate continuous integration (CI)  -- something that few current CI services offer for a reasonable cost. That left us with three options: GitHub Actions are free and have easy integration with the Cholla GitHub repository but have no GPUs, GitLab CI has GPUs but can be challenging to integrate with GitHub, and hosting our own CI system. We ended up running the builds and static analyzers only, without running the tests, on GitHub Actions while a self hosted Jenkins instance was set up to run the tests on local GPU resources at the University of Pittsburgh Center for Research Computing (CRC). In the final configuration several jobs are launched on every pull request: A GitHub Actions job to check code formatting, a GitHub actions matrix job to build all the HIP/AMD builds, and a Jenkins matrix job running on CRC hardware that runs the CUDA builds, tests, and static analyzers. Thus, every common configuration of Cholla is built with both CUDA and HIP on every pull request and the CUDA builds are also tested to ensure that no existing or new tests fail. 



